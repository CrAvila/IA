{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwqNO/d1vp8PssqCAd8TDC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CrAvila/IA/blob/main/Taller1/Stroke_PM_Front.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSYN5MDoGM3L"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify inputs from the user\n",
        "def classify_input(value, config):\n",
        "    ranges = config[\"ranges\"]\n",
        "    categories = config[\"categories\"]\n",
        "    for i, (start, end) in enumerate(ranges):\n",
        "        if start <= value < end:\n",
        "            return categories[i]\n",
        "    return categories[-1]"
      ],
      "metadata": {
        "id": "PqwM7ha9SjDw"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import random\n",
        "from itertools import combinations\n",
        "\n",
        "data = pd.read_csv('https://drive.google.com/uc?export=download&id=1NYlG6ZYmh-TdHgEuzTz1K-yfFxIoFEUC')\n",
        "\n",
        "# Events defined in the model\n",
        "events = {\n",
        "    \"quantitative\" : {\n",
        "\n",
        "        \"age\": {\n",
        "            \"ranges\" : [\n",
        "                (0,18),\n",
        "                (18,65),\n",
        "                (65, float('inf'))\n",
        "            ],\n",
        "\n",
        "            \"categories\" : [\n",
        "                'Child',\n",
        "                'Adult',\n",
        "                'Senior'\n",
        "            ]\n",
        "        },\n",
        "\n",
        "        \"avg_glucose_level\": {\n",
        "            \"ranges\" : [\n",
        "                (0,80),\n",
        "                (80,120),\n",
        "                (120, float('inf'))\n",
        "            ],\n",
        "\n",
        "            \"categories\" : [\n",
        "                'Low',\n",
        "                'Normal',\n",
        "                'High'\n",
        "            ]\n",
        "        },\n",
        "\n",
        "        \"bmi\": {\n",
        "            \"ranges\": [\n",
        "                (0,18.5),\n",
        "                (18.5, 25),\n",
        "                (25, float('inf'))\n",
        "            ],\n",
        "\n",
        "            \"categories\": [\n",
        "                'Underweight',\n",
        "                'Normal',\n",
        "                'Overweight',\n",
        "                'Unknown'\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"qualitative\" :  {\n",
        "        \"gender\" : data['gender'].unique().tolist(),\n",
        "        \"work_type\": data['work_type'].unique().tolist(),\n",
        "        \"Residence_type\" : data['Residence_type'].unique().tolist(),\n",
        "        \"smoking_status\" : data['smoking_status'].unique().tolist()\n",
        "    },\n",
        "\n",
        "    \"boolean\" : {\n",
        "        \"hypertension\" : {\n",
        "            \"statuses\" : [0,1]\n",
        "        },\n",
        "\n",
        "        \"heart_disease\" : {\n",
        "            \"statuses\" : [0,1]\n",
        "        },\n",
        "\n",
        "        \"ever_married\" : {\n",
        "            \"statuses\" : [0,1]\n",
        "        } ,\n",
        "\n",
        "        \"stroke\" : {\n",
        "            \"statuses\" : [0,1]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "#Function to process original data\n",
        "def process_data(df, variables_to_use):\n",
        "\n",
        "    processed_dataframe = df.copy()\n",
        "\n",
        "    #Classify que quantitative values\n",
        "    for quantitative_column in list(events['quantitative'].keys()):\n",
        "\n",
        "        #Specific function to classify the column value\n",
        "        def categorize(value):\n",
        "            if isinstance(value, int) or isinstance(value, float):\n",
        "                for i, (lower, upper) in enumerate(events[\"quantitative\"][quantitative_column][\"ranges\"]):\n",
        "                    if lower <= value < upper:\n",
        "                        return events[\"quantitative\"][quantitative_column][\"categories\"][i]\n",
        "            else:\n",
        "                return value\n",
        "\n",
        "        # Replace value into the processed dataframe\n",
        "        processed_dataframe[quantitative_column] = processed_dataframe[quantitative_column].apply(categorize)\n",
        "\n",
        "    replace_mapping = {\n",
        "        \"No\" : 0,\n",
        "        \"Yes\" : 1\n",
        "    }\n",
        "\n",
        "    processed_dataframe['ever_married'] = processed_dataframe['ever_married'].replace(replace_mapping)\n",
        "\n",
        "    new_columns = [col for col in variables_to_use]\n",
        "    new_columns.append('stroke')\n",
        "\n",
        "    cols_to_drop = [col for col in data.columns.values.tolist() if col not in new_columns]\n",
        "    cols_to_drop = [col for col in cols_to_drop if col in processed_dataframe.columns.tolist()]\n",
        "\n",
        "    processed_dataframe = processed_dataframe.drop(columns=cols_to_drop)\n",
        "    processed_dataframe.fillna('Unknown', inplace=True)\n",
        "\n",
        "    processed_dataframe = processed_dataframe[new_columns]\n",
        "\n",
        "    return processed_dataframe\n",
        "\n",
        "def split_data(df, test_percentage):\n",
        "    # Separate data into stroke and no stroke groups\n",
        "    stroke_group = df[df['stroke'] == 1]\n",
        "    no_stroke_group = df[df['stroke'] == 0]\n",
        "\n",
        "    # Shuffle records in both groups\n",
        "    stroke_group_shuffled = stroke_group.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    no_stroke_group_shuffled = no_stroke_group.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # Calculate the number of records needed for 20 %\n",
        "    num_test_stroke = int(test_percentage * len(stroke_group_shuffled))\n",
        "    num_test_no_stroke = int(test_percentage * len(no_stroke_group_shuffled))\n",
        "\n",
        "    # Create test and training sets for the no stroke group\n",
        "    test_set_no_stroke = no_stroke_group_shuffled[:num_test_no_stroke]\n",
        "    train_set_no_stroke = no_stroke_group_shuffled[num_test_no_stroke:]\n",
        "\n",
        "    # Create test and training set for the stroke group\n",
        "    test_set_stroke = stroke_group_shuffled[:num_test_stroke]\n",
        "    train_set_stroke = stroke_group_shuffled[num_test_stroke:]\n",
        "\n",
        "    # Combine test sets\n",
        "    final_test_set = pd.concat([test_set_stroke, test_set_no_stroke])\n",
        "\n",
        "    # Combine train sets\n",
        "    final_train_set = pd.concat([train_set_stroke, train_set_no_stroke])\n",
        "\n",
        "    return final_test_set, final_train_set\n",
        "\n",
        "variables_to_use = [\n",
        "    'age',\n",
        "    'avg_glucose_level',\n",
        "    'bmi',\n",
        "    'hypertension',\n",
        "    'heart_disease',\n",
        "]\n",
        "\n",
        "processed_data = process_data(data, variables_to_use)\n",
        "test_set, train_set = split_data(processed_data, 0.2)\n",
        "\n",
        "def build_tree(data):\n",
        "\n",
        "    count_dict = {}\n",
        "    prob_dict = {}\n",
        "\n",
        "    unique_values_dict = {\n",
        "        column: data[column].unique().tolist() for column in data.columns\n",
        "    }\n",
        "\n",
        "    def calculate_probabilities(df, values_dict, conditions=(), index=0, accumulated_prob=1.0, prob_dict={}):\n",
        "\n",
        "        # Return when the current variable is the last one\n",
        "        if index == len(categories):\n",
        "            return\n",
        "\n",
        "        # Get current categories and values\n",
        "        current_category = categories[index]\n",
        "        current_values = values_dict[current_category]\n",
        "\n",
        "        # Iterate though current values\n",
        "        for value in current_values:\n",
        "            new_conditions = conditions + ((current_category, value),)\n",
        "\n",
        "            filtered_df = df\n",
        "            for condition in new_conditions:\n",
        "                column, val = condition\n",
        "                filtered_df = filtered_df[filtered_df[column] == val]\n",
        "\n",
        "            # Calculate the count and probability of current branch, if the count is zero then divide by 1\n",
        "            count = len(filtered_df)\n",
        "            prob = count / (len(df) or 1)\n",
        "            branch_prob = accumulated_prob * prob\n",
        "\n",
        "            if index not in prob_dict:\n",
        "                prob_dict[index] = {}\n",
        "                count_dict[index] = {}\n",
        "\n",
        "            # Store the count and the probability of the branch\n",
        "            prob_dict[index][new_conditions] = branch_prob\n",
        "            count_dict[index][new_conditions] = count\n",
        "\n",
        "            next_index = index + 1\n",
        "            calculate_probabilities(filtered_df, values_dict, new_conditions, next_index, accumulated_prob, prob_dict)\n",
        "\n",
        "    # Get categories\n",
        "    categories = list(unique_values_dict.keys())\n",
        "    # Calculate probabilities and counts of next branch\n",
        "    calculate_probabilities(data, unique_values_dict, prob_dict=prob_dict)\n",
        "\n",
        "    return count_dict, prob_dict\n",
        "\n",
        "# Calculate counts and probabilities as a tree\n",
        "count_tree, probability_tree = build_tree(train_set)\n",
        "\n",
        "def get_probability(model, variables, input_data, events):\n",
        "\n",
        "    # Categorize the quantitative variables\n",
        "    def get_from_tree(variable, value, events):\n",
        "        if isinstance(value, str):\n",
        "            return value\n",
        "\n",
        "        if variable in events['quantitative']:\n",
        "            ranges = events['quantitative'][variable]['ranges']\n",
        "            categories = events['quantitative'][variable]['categories']\n",
        "            for i, (lower, upper) in enumerate(ranges):\n",
        "                if lower <= value < upper:\n",
        "                    return categories[i]\n",
        "        return value\n",
        "\n",
        "    # Create the tuple of tuples for the input\n",
        "    categorized_input = []\n",
        "    for variable, value in zip(variables, input_data):\n",
        "        categorized_value = get_from_tree(variable, value, events)\n",
        "        categorized_input.append(categorized_value)\n",
        "\n",
        "    input_tuple = tuple((variable, value) for variable, value in zip(variables,categorized_input))\n",
        "\n",
        "    # Specific for this model\n",
        "    key = input_tuple + (('stroke', 1),)\n",
        "\n",
        "    # Extract probability\n",
        "    probability = model[len(variables)][key]\n",
        "\n",
        "    return probability\n",
        "\n",
        "\n",
        "\n",
        "def get_stroke_risk(model, variables, input_data):\n",
        "    probability = get_probability(model, variables, input_data, events)\n",
        "    rgn = random()\n",
        "\n",
        "    risk = 0\n",
        "\n",
        "    if rgn < probability or probability > 0.05:\n",
        "        risk = 1\n",
        "\n",
        "    return risk, probability"
      ],
      "metadata": {
        "id": "uQaVFabrVk92"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_stroke(age, avg_glucose_average, bmi_value, bmi_known, hypertension, heart_disease):\n",
        "    # Classify the input features\n",
        "    age_category = classify_input(age, events[\"quantitative\"][\"age\"])\n",
        "    glucose_category = classify_input(avg_glucose_average, events[\"quantitative\"][\"avg_glucose_level\"])\n",
        "\n",
        "    bmi_config = events[\"quantitative\"][\"bmi\"]\n",
        "    bmi_category = \"Unknown\" if bmi_known else classify_input(bmi_value, bmi_config)\n",
        "    hypertension = 1 if hypertension else 0\n",
        "    heart_disease = 1 if heart_disease else 0\n",
        "\n",
        "    inputs = [age_category, glucose_category, bmi_category, hypertension, heart_disease]\n",
        "    r, p = get_stroke_risk(probability_tree, variables_to_use, inputs)\n",
        "    pf = \"{:.2%}\".format(p)\n",
        "\n",
        "    # Your prediction logic here\n",
        "    prediction_result = f\"You are{' ' if r == 1 else ' not '}at risk of a stroke.\"\n",
        "    desc = f\"{pf} of people with these characteristics suffered a stroke.\"\n",
        "\n",
        "    return prediction_result, desc\n",
        "\n",
        "with gr.Blocks() as app:\n",
        "    age = gr.Number(label=\"Age\")\n",
        "    avg_glucose_average = gr.Number(label=\"Average Glucose\")\n",
        "    bmi_value = gr.Number(label=\"Body Mass Index\", default=None)\n",
        "    bmi_known = gr.Checkbox(label=\"I don't know my BMI\")\n",
        "    hypertension = gr.Checkbox(label=\"Hypertension\")\n",
        "    heart_disease = gr.Checkbox(label=\"Heart Disease\")\n",
        "\n",
        "    output = [gr.Textbox(label=\"Stroke Prediction\"),\n",
        "              gr.Textbox(label=\"Description\")]\n",
        "\n",
        "    predict_btn = gr.Button(\"Predict\")\n",
        "    predict_btn.click(fn=predict_stroke, inputs=[age, avg_glucose_average, bmi_value, bmi_known, hypertension, heart_disease], outputs=output)\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "XC0opseTGg62",
        "outputId": "96470d57-e152-49bc-8f35-ed108a36aa94"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-60-9c49f4859ce3>:24: GradioUnusedKwargWarning: You have unused kwarg parameters in Number, please remove them: {'default': None}\n",
            "  bmi_value = gr.Number(label=\"Body Mass Index\", default=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7888, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mGcFkwR2a8yM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}